{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7d66d0-82b9-4f5d-889e-eca7b9ee019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/dnp/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package punkt to /home/dnp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/dnp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dnp/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: ['I love exploring the latest advancements in artificial intelligence.', 'The rapid evolution of machine learning models fascinates me.', 'Companies are integrating AI into everyday applications like virtual assistants and chatbots.', 'Healthcare is benefiting from AI-driven diagnostics and predictive analytics.', 'It excites me to see how technology can improve lives.', 'The potential for innovation in this field is endless.']\n",
      "Words: ['i', 'love', 'exploring', 'the', 'latest', 'advancements', 'in', 'artificial', 'intelligence', 'the', 'rapid', 'evolution', 'of', 'machine', 'learning', 'models', 'fascinates', 'me', 'companies', 'are', 'integrating', 'ai', 'into', 'everyday', 'applications', 'like', 'virtual', 'assistants', 'and', 'chatbots', 'healthcare', 'is', 'benefiting', 'from', 'aidriven', 'diagnostics', 'and', 'predictive', 'analytics', 'it', 'excites', 'me', 'to', 'see', 'how', 'technology', 'can', 'improve', 'lives', 'the', 'potential', 'for', 'innovation', 'in', 'this', 'field', 'is', 'endless']\n",
      "Words without stopwords: ['love', 'exploring', 'latest', 'advancements', 'artificial', 'intelligence', 'rapid', 'evolution', 'machine', 'learning', 'models', 'fascinates', 'companies', 'integrating', 'ai', 'everyday', 'applications', 'like', 'virtual', 'assistants', 'chatbots', 'healthcare', 'benefiting', 'aidriven', 'diagnostics', 'predictive', 'analytics', 'excites', 'see', 'technology', 'improve', 'lives', 'potential', 'innovation', 'field', 'endless']\n",
      "Frequency Distribution: [('love', 1), ('exploring', 1), ('latest', 1), ('advancements', 1), ('artificial', 1), ('intelligence', 1), ('rapid', 1), ('evolution', 1), ('machine', 1), ('learning', 1), ('models', 1), ('fascinates', 1), ('companies', 1), ('integrating', 1), ('ai', 1), ('everyday', 1), ('applications', 1), ('like', 1), ('virtual', 1), ('assistants', 1), ('chatbots', 1), ('healthcare', 1), ('benefiting', 1), ('aidriven', 1), ('diagnostics', 1), ('predictive', 1), ('analytics', 1), ('excites', 1), ('see', 1), ('technology', 1), ('improve', 1), ('lives', 1), ('potential', 1), ('innovation', 1), ('field', 1), ('endless', 1)]\n",
      "Porter Stemming: ['love', 'explor', 'latest', 'advanc', 'artifici', 'intellig', 'rapid', 'evolut', 'machin', 'learn', 'model', 'fascin', 'compani', 'integr', 'ai', 'everyday', 'applic', 'like', 'virtual', 'assist', 'chatbot', 'healthcar', 'benefit', 'aidriven', 'diagnost', 'predict', 'analyt', 'excit', 'see', 'technolog', 'improv', 'live', 'potenti', 'innov', 'field', 'endless']\n",
      "Lancaster Stemming: ['lov', 'expl', 'latest', 'adv', 'art', 'intellig', 'rapid', 'evolv', 'machin', 'learn', 'model', 'fascin', 'company', 'integr', 'ai', 'everyday', 'apply', 'lik', 'virt', 'assist', 'chatbot', 'healthc', 'benefit', 'aidr', 'diagnost', 'predict', 'analys', 'excit', 'see', 'technolog', 'improv', 'liv', 'pot', 'innov', 'field', 'endless']\n",
      "Lemmatization: ['love', 'exploring', 'latest', 'advancement', 'artificial', 'intelligence', 'rapid', 'evolution', 'machine', 'learning', 'model', 'fascinates', 'company', 'integrating', 'ai', 'everyday', 'application', 'like', 'virtual', 'assistant', 'chatbots', 'healthcare', 'benefiting', 'aidriven', 'diagnostics', 'predictive', 'analytics', 'excites', 'see', 'technology', 'improve', 'life', 'potential', 'innovation', 'field', 'endless']\n",
      "Words with >5 letters: ['exploring', 'latest', 'advancements', 'artificial', 'intelligence', 'evolution', 'machine', 'learning', 'models', 'fascinates', 'Companies', 'integrating', 'everyday', 'applications', 'virtual', 'assistants', 'chatbots', 'Healthcare', 'benefiting', 'driven', 'diagnostics', 'predictive', 'analytics', 'excites', 'technology', 'improve', 'potential', 'innovation', 'endless']\n",
      "Numbers: []\n",
      "Capitalized words: ['I', 'The', 'Companies', 'Healthcare', 'It', 'The']\n",
      "Alphabet-only words: ['I', 'love', 'exploring', 'the', 'latest', 'advancements', 'in', 'artificial', 'intelligence', 'The', 'rapid', 'evolution', 'of', 'machine', 'learning', 'models', 'fascinates', 'me', 'Companies', 'are', 'integrating', 'AI', 'into', 'everyday', 'applications', 'like', 'virtual', 'assistants', 'and', 'chatbots', 'Healthcare', 'is', 'benefiting', 'from', 'AI', 'driven', 'diagnostics', 'and', 'predictive', 'analytics', 'It', 'excites', 'me', 'to', 'see', 'how', 'technology', 'can', 'improve', 'lives', 'The', 'potential', 'for', 'innovation', 'in', 'this', 'field', 'is', 'endless']\n",
      "Words starting with vowel: ['I', 'exploring', 'advancements', 'in', 'artificial', 'intelligence', 'evolution', 'of', 'are', 'integrating', 'AI', 'into', 'everyday', 'applications', 'assistants', 'and', 'is', 'AI', 'and', 'analytics', 'It', 'excites', 'improve', 'innovation', 'in', 'is', 'endless']\n",
      "Custom tokens: ['I', 'love', 'exploring', 'the', 'latest', 'advancements', 'in', 'artificial', 'intelligence', 'The', 'rapid', 'evolution', 'of', 'machine', 'learning', 'models', 'fascinates', 'me', 'Companies', 'are', 'integrating', 'AI', 'into', 'everyday', 'applications', 'like', 'virtual', 'assistants', 'and', 'chatbots', 'Healthcare', 'is', 'benefiting', 'from', 'AI-driven', 'diagnostics', 'and', 'predictive', 'analytics', 'It', 'excites', 'me', 'to', 'see', 'how', 'technology', 'can', 'improve', 'lives', 'The', 'potential', 'for', 'innovation', 'in', 'this', 'field', 'is', 'endless']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt_tab') #apparently you need this before downloading punkt\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "text = \"I love exploring the latest advancements in artificial intelligence. The rapid evolution of machine learning models fascinates me. Companies are integrating AI into everyday applications like virtual assistants and chatbots. Healthcare is benefiting from AI-driven diagnostics and predictive analytics. It excites me to see how technology can improve lives. The potential for innovation in this field is endless.\"\n",
    "\n",
    "# Q1\n",
    "low = text.lower()\n",
    "no_punc = re.sub(r'[^\\w\\s]', '', low)\n",
    "s = sent_tokenize(text)\n",
    "w = word_tokenize(no_punc)\n",
    "sw = set(stopwords.words('english'))\n",
    "ns_w = [t for t in w if t not in sw]\n",
    "freq = nltk.FreqDist(ns_w)\n",
    "print(\"Sentences:\", s)\n",
    "print(\"Words:\", w)\n",
    "print(\"Words without stopwords:\", ns_w)\n",
    "print(\"Frequency Distribution:\", freq.most_common())\n",
    "\n",
    "# Q2\n",
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()\n",
    "le = WordNetLemmatizer()\n",
    "stem_p = [ps.stem(t) for t in ns_w]\n",
    "stem_l = [ls.stem(t) for t in ns_w]\n",
    "lemma = [le.lemmatize(t) for t in ns_w]\n",
    "print(\"Porter Stemming:\", stem_p)\n",
    "print(\"Lancaster Stemming:\", stem_l)\n",
    "print(\"Lemmatization:\", lemma)\n",
    "\n",
    "# Q3\n",
    "gt5 = re.findall(r'\\b\\w{6,}\\b', text)\n",
    "nums = re.findall(r'\\d+', text)\n",
    "caps = re.findall(r'\\b[A-Z][a-z]*\\b', text)\n",
    "alpha = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
    "vow = re.findall(r'\\b[AEIOUaeiou]\\w*', text)\n",
    "print(\"Words with >5 letters:\", gt5)\n",
    "print(\"Numbers:\", nums)\n",
    "print(\"Capitalized words:\", caps)\n",
    "print(\"Alphabet-only words:\", alpha)\n",
    "print(\"Words starting with vowel:\", vow)\n",
    "\n",
    "# Q4\n",
    "def tokenize(t):\n",
    "    t = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', t)\n",
    "    t = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', t)\n",
    "    t = re.sub(r'\\+?\\d{1,3}[\\s-]\\d{6,10}', '<PHONE>', t)\n",
    "    return re.findall(r'(?:\\d+\\.\\d+|\\w+(?:[-\\']\\w+)*)', t)\n",
    "\n",
    "tokens = tokenize(text)\n",
    "print(\"Custom tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16cfa2-3b4c-4a49-b6af-d4c47b32f92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
